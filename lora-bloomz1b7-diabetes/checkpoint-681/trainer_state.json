{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9906439185470557,
  "eval_steps": 500,
  "global_step": 681,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04402861860209136,
      "grad_norm": 0.309226393699646,
      "learning_rate": 0.00019735682819383262,
      "loss": 2.2284,
      "step": 10
    },
    {
      "epoch": 0.08805723720418272,
      "grad_norm": 0.4431345760822296,
      "learning_rate": 0.0001944199706314244,
      "loss": 2.0161,
      "step": 20
    },
    {
      "epoch": 0.13208585580627408,
      "grad_norm": 0.33410605788230896,
      "learning_rate": 0.00019148311306901617,
      "loss": 1.8867,
      "step": 30
    },
    {
      "epoch": 0.17611447440836545,
      "grad_norm": 0.5046488046646118,
      "learning_rate": 0.00018854625550660794,
      "loss": 1.8036,
      "step": 40
    },
    {
      "epoch": 0.2201430930104568,
      "grad_norm": 0.3600675165653229,
      "learning_rate": 0.00018560939794419972,
      "loss": 1.7937,
      "step": 50
    },
    {
      "epoch": 0.26417171161254815,
      "grad_norm": 0.4870322346687317,
      "learning_rate": 0.0001826725403817915,
      "loss": 1.6247,
      "step": 60
    },
    {
      "epoch": 0.3082003302146395,
      "grad_norm": 0.5450774431228638,
      "learning_rate": 0.00017973568281938327,
      "loss": 1.6134,
      "step": 70
    },
    {
      "epoch": 0.3522289488167309,
      "grad_norm": 0.5806477665901184,
      "learning_rate": 0.00017679882525697504,
      "loss": 1.5947,
      "step": 80
    },
    {
      "epoch": 0.39625756741882223,
      "grad_norm": 0.5201717615127563,
      "learning_rate": 0.00017386196769456682,
      "loss": 1.6414,
      "step": 90
    },
    {
      "epoch": 0.4402861860209136,
      "grad_norm": 0.4812537729740143,
      "learning_rate": 0.0001709251101321586,
      "loss": 1.6026,
      "step": 100
    },
    {
      "epoch": 0.48431480462300497,
      "grad_norm": 0.4439701735973358,
      "learning_rate": 0.00016798825256975037,
      "loss": 1.5422,
      "step": 110
    },
    {
      "epoch": 0.5283434232250963,
      "grad_norm": 0.48656028509140015,
      "learning_rate": 0.00016505139500734215,
      "loss": 1.5505,
      "step": 120
    },
    {
      "epoch": 0.5723720418271877,
      "grad_norm": 0.610037088394165,
      "learning_rate": 0.00016211453744493392,
      "loss": 1.4911,
      "step": 130
    },
    {
      "epoch": 0.616400660429279,
      "grad_norm": 0.5180946588516235,
      "learning_rate": 0.0001591776798825257,
      "loss": 1.6727,
      "step": 140
    },
    {
      "epoch": 0.6604292790313704,
      "grad_norm": 0.47669655084609985,
      "learning_rate": 0.00015624082232011747,
      "loss": 1.6034,
      "step": 150
    },
    {
      "epoch": 0.7044578976334618,
      "grad_norm": 0.3975149691104889,
      "learning_rate": 0.00015330396475770925,
      "loss": 1.4897,
      "step": 160
    },
    {
      "epoch": 0.7484865162355531,
      "grad_norm": 0.5044145584106445,
      "learning_rate": 0.00015036710719530102,
      "loss": 1.4347,
      "step": 170
    },
    {
      "epoch": 0.7925151348376445,
      "grad_norm": 0.53238445520401,
      "learning_rate": 0.0001474302496328928,
      "loss": 1.5435,
      "step": 180
    },
    {
      "epoch": 0.8365437534397359,
      "grad_norm": 0.5428708791732788,
      "learning_rate": 0.00014449339207048457,
      "loss": 1.5226,
      "step": 190
    },
    {
      "epoch": 0.8805723720418271,
      "grad_norm": 0.5349464416503906,
      "learning_rate": 0.00014155653450807635,
      "loss": 1.5863,
      "step": 200
    },
    {
      "epoch": 0.9246009906439185,
      "grad_norm": 0.4647069275379181,
      "learning_rate": 0.00013861967694566812,
      "loss": 1.4404,
      "step": 210
    },
    {
      "epoch": 0.9686296092460099,
      "grad_norm": 0.5696597695350647,
      "learning_rate": 0.00013568281938325992,
      "loss": 1.568,
      "step": 220
    },
    {
      "epoch": 1.0088057237204182,
      "grad_norm": 0.5111461281776428,
      "learning_rate": 0.0001327459618208517,
      "loss": 1.3866,
      "step": 230
    },
    {
      "epoch": 1.0528343423225097,
      "grad_norm": 0.5631775856018066,
      "learning_rate": 0.00012980910425844348,
      "loss": 1.4432,
      "step": 240
    },
    {
      "epoch": 1.096862960924601,
      "grad_norm": 0.5331035256385803,
      "learning_rate": 0.00012687224669603525,
      "loss": 1.475,
      "step": 250
    },
    {
      "epoch": 1.1408915795266923,
      "grad_norm": 0.5985906720161438,
      "learning_rate": 0.00012393538913362703,
      "loss": 1.4445,
      "step": 260
    },
    {
      "epoch": 1.1849201981287838,
      "grad_norm": 0.6071798205375671,
      "learning_rate": 0.00012099853157121881,
      "loss": 1.2935,
      "step": 270
    },
    {
      "epoch": 1.228948816730875,
      "grad_norm": 0.5207014679908752,
      "learning_rate": 0.00011806167400881059,
      "loss": 1.3743,
      "step": 280
    },
    {
      "epoch": 1.2729774353329664,
      "grad_norm": 0.6668779850006104,
      "learning_rate": 0.00011512481644640237,
      "loss": 1.4054,
      "step": 290
    },
    {
      "epoch": 1.3170060539350579,
      "grad_norm": 0.5818060636520386,
      "learning_rate": 0.00011218795888399414,
      "loss": 1.4949,
      "step": 300
    },
    {
      "epoch": 1.3610346725371492,
      "grad_norm": 0.7023141980171204,
      "learning_rate": 0.00010925110132158592,
      "loss": 1.5164,
      "step": 310
    },
    {
      "epoch": 1.4050632911392404,
      "grad_norm": 0.6771798133850098,
      "learning_rate": 0.00010631424375917769,
      "loss": 1.4336,
      "step": 320
    },
    {
      "epoch": 1.4490919097413317,
      "grad_norm": 0.6510696411132812,
      "learning_rate": 0.00010337738619676947,
      "loss": 1.3349,
      "step": 330
    },
    {
      "epoch": 1.4931205283434232,
      "grad_norm": 0.5799066424369812,
      "learning_rate": 0.00010044052863436124,
      "loss": 1.4092,
      "step": 340
    },
    {
      "epoch": 1.5371491469455147,
      "grad_norm": 0.6413989067077637,
      "learning_rate": 9.750367107195302e-05,
      "loss": 1.501,
      "step": 350
    },
    {
      "epoch": 1.581177765547606,
      "grad_norm": 0.49674203991889954,
      "learning_rate": 9.456681350954479e-05,
      "loss": 1.4126,
      "step": 360
    },
    {
      "epoch": 1.6252063841496973,
      "grad_norm": 0.586134135723114,
      "learning_rate": 9.162995594713657e-05,
      "loss": 1.3862,
      "step": 370
    },
    {
      "epoch": 1.6692350027517886,
      "grad_norm": 0.6304879188537598,
      "learning_rate": 8.869309838472834e-05,
      "loss": 1.2756,
      "step": 380
    },
    {
      "epoch": 1.7132636213538799,
      "grad_norm": 0.7248802781105042,
      "learning_rate": 8.575624082232012e-05,
      "loss": 1.3865,
      "step": 390
    },
    {
      "epoch": 1.7572922399559714,
      "grad_norm": 0.6658776998519897,
      "learning_rate": 8.281938325991189e-05,
      "loss": 1.387,
      "step": 400
    },
    {
      "epoch": 1.801320858558063,
      "grad_norm": 0.6294355392456055,
      "learning_rate": 7.988252569750367e-05,
      "loss": 1.3745,
      "step": 410
    },
    {
      "epoch": 1.8453494771601542,
      "grad_norm": 0.6488150358200073,
      "learning_rate": 7.694566813509546e-05,
      "loss": 1.5033,
      "step": 420
    },
    {
      "epoch": 1.8893780957622455,
      "grad_norm": 0.5808541774749756,
      "learning_rate": 7.400881057268723e-05,
      "loss": 1.3329,
      "step": 430
    },
    {
      "epoch": 1.9334067143643368,
      "grad_norm": 0.7806224822998047,
      "learning_rate": 7.107195301027901e-05,
      "loss": 1.4793,
      "step": 440
    },
    {
      "epoch": 1.977435332966428,
      "grad_norm": 0.7872346639633179,
      "learning_rate": 6.813509544787078e-05,
      "loss": 1.4162,
      "step": 450
    },
    {
      "epoch": 2.0176114474408364,
      "grad_norm": 0.595707356929779,
      "learning_rate": 6.519823788546256e-05,
      "loss": 1.3325,
      "step": 460
    },
    {
      "epoch": 2.0616400660429277,
      "grad_norm": 0.6738773584365845,
      "learning_rate": 6.226138032305433e-05,
      "loss": 1.3194,
      "step": 470
    },
    {
      "epoch": 2.1056686846450194,
      "grad_norm": 0.5501164793968201,
      "learning_rate": 5.932452276064611e-05,
      "loss": 1.3639,
      "step": 480
    },
    {
      "epoch": 2.1496973032471107,
      "grad_norm": 0.660592794418335,
      "learning_rate": 5.63876651982379e-05,
      "loss": 1.3756,
      "step": 490
    },
    {
      "epoch": 2.193725921849202,
      "grad_norm": 0.5843337178230286,
      "learning_rate": 5.345080763582967e-05,
      "loss": 1.3063,
      "step": 500
    },
    {
      "epoch": 2.2377545404512933,
      "grad_norm": 0.5946432948112488,
      "learning_rate": 5.051395007342145e-05,
      "loss": 1.3255,
      "step": 510
    },
    {
      "epoch": 2.2817831590533846,
      "grad_norm": 0.6395003795623779,
      "learning_rate": 4.7577092511013216e-05,
      "loss": 1.4707,
      "step": 520
    },
    {
      "epoch": 2.325811777655476,
      "grad_norm": 0.8102002143859863,
      "learning_rate": 4.4640234948605e-05,
      "loss": 1.321,
      "step": 530
    },
    {
      "epoch": 2.3698403962575676,
      "grad_norm": 0.6434851288795471,
      "learning_rate": 4.170337738619677e-05,
      "loss": 1.2293,
      "step": 540
    },
    {
      "epoch": 2.413869014859659,
      "grad_norm": 0.8348950743675232,
      "learning_rate": 3.876651982378855e-05,
      "loss": 1.2524,
      "step": 550
    },
    {
      "epoch": 2.45789763346175,
      "grad_norm": 0.61674964427948,
      "learning_rate": 3.582966226138032e-05,
      "loss": 1.3365,
      "step": 560
    },
    {
      "epoch": 2.5019262520638414,
      "grad_norm": 0.9142128229141235,
      "learning_rate": 3.28928046989721e-05,
      "loss": 1.3127,
      "step": 570
    },
    {
      "epoch": 2.5459548706659327,
      "grad_norm": 1.0223573446273804,
      "learning_rate": 2.9955947136563877e-05,
      "loss": 1.1706,
      "step": 580
    },
    {
      "epoch": 2.5899834892680245,
      "grad_norm": 0.8382899165153503,
      "learning_rate": 2.7019089574155652e-05,
      "loss": 1.3412,
      "step": 590
    },
    {
      "epoch": 2.6340121078701157,
      "grad_norm": 0.6401752233505249,
      "learning_rate": 2.408223201174743e-05,
      "loss": 1.3994,
      "step": 600
    },
    {
      "epoch": 2.678040726472207,
      "grad_norm": 0.7643277049064636,
      "learning_rate": 2.114537444933921e-05,
      "loss": 1.2204,
      "step": 610
    },
    {
      "epoch": 2.7220693450742983,
      "grad_norm": 0.7217891812324524,
      "learning_rate": 1.8208516886930985e-05,
      "loss": 1.4031,
      "step": 620
    },
    {
      "epoch": 2.7660979636763896,
      "grad_norm": 0.5675274729728699,
      "learning_rate": 1.527165932452276e-05,
      "loss": 1.3165,
      "step": 630
    },
    {
      "epoch": 2.810126582278481,
      "grad_norm": 0.6969950795173645,
      "learning_rate": 1.2334801762114539e-05,
      "loss": 1.2697,
      "step": 640
    },
    {
      "epoch": 2.854155200880572,
      "grad_norm": 0.6501559019088745,
      "learning_rate": 9.397944199706314e-06,
      "loss": 1.4586,
      "step": 650
    },
    {
      "epoch": 2.8981838194826635,
      "grad_norm": 1.0523760318756104,
      "learning_rate": 6.461086637298092e-06,
      "loss": 1.3586,
      "step": 660
    },
    {
      "epoch": 2.942212438084755,
      "grad_norm": 0.7892823815345764,
      "learning_rate": 3.5242290748898685e-06,
      "loss": 1.3311,
      "step": 670
    },
    {
      "epoch": 2.9862410566868465,
      "grad_norm": 0.8388402462005615,
      "learning_rate": 5.873715124816446e-07,
      "loss": 1.3471,
      "step": 680
    }
  ],
  "logging_steps": 10,
  "max_steps": 681,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.045616825814221e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
